from DeepQNetwork.dqn_utils import visualize_training_loss

if __name__=="__main__":


    # def visualize_training_loss(input_file, title, output_file):


    # Scenario 1
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario1/'
                                       'average_immovable_loss_history_scenario1_gamma0.25.txt',
                                           output_file='./loss_history/immovable_agent'
                                                        '_training_loss_scenario1_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario1/'
                                       'average_movable_loss_history_scenario1_gamma0.25.txt',
                                           output_file='./loss_history/movable_agent'
                                                        '_training_loss_scenario1_boltzmann.png')

    # Scenario 2
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario2/'
                                       'average_immovable_loss_history_scenario2_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario2_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario2/'
                                                      'average_movable_loss_history_scenario2_gamma0.25.txt',
                                           output_file='./loss_history/movable_agent'
                                                       '_training_loss_scenario2_boltzmann.png')

    # Scenario 3
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario3/'
                                       'average_immovable_loss_history_scenario3_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario3_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario3/'
                                       'average_movable_loss_history_scenario3_gamma0.25.txt',
                            output_file='./loss_history/movable_agent'
                                        '_training_loss_scenario3_boltzmann.png')

    # Scenario 4
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario4/'
                                       'average_immovable_loss_history_scenario4_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario4_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario4/'
                                       'average_movable_loss_history_scenario4_gamma0.25.txt',
                            output_file='./loss_history/movable_agent'
                                        '_training_loss_scenario4_boltzmann.png')

    # Scenario 5
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario5/'
                                       'average_immovable_loss_history_scenario5_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario5_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario5/'
                                       'average_movable_loss_history_scenario5_gamma0.25.txt',
                            output_file='./loss_history/movable_agent'
                                        '_training_loss_scenario5_boltzmann.png')

    # Scenario 6
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario6/'
                                       'average_immovable_loss_history_scenario6_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario6_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario6/'
                                       'average_movable_loss_history_scenario6_gamma0.25.txt',
                            output_file='./loss_history/movable_agent'
                                        '_training_loss_scenario6_boltzmann.png')

    # Scenario 7
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario7/'
                                       'average_immovable_loss_history_scenario7_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario7_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario7/'
                                       'average_movable_loss_history_scenario7_gamma0.25.txt',
                            output_file='./loss_history/movable_agent'
                                        '_training_loss_scenario7_boltzmann.png')

    # Scenario 8
    # Huber Loss and MSE Loss for RL_I
    # Boltzmann for the RL_I Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario8/'
                                       'average_immovable_loss_history_scenario8_gamma0.25.txt',
                            output_file='./loss_history/immovable_agent'
                                        '_training_loss_scenario8_boltzmann.png')

    # Same for the RL_M Agent
    visualize_training_loss(input_file='./outputs_testDQN_Boltzmann/scenario8/'
                                       'average_movable_loss_history_scenario8_gamma0.25.txt',
                            output_file='./loss_history/movable_agent'
                                        '_training_loss_scenario8_boltzmann.png')